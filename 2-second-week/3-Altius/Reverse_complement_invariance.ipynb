{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding reverse complement invariance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Base pair sequences can be encoded in a variety of different ways (*e.g.,* `TATAAGC...`). For machine learning applications, a commonly used encoding is a *one-hot* encoding: the same sequence above can be represented as the matrix\n",
    "$$\n",
    "\\begin{array}{c}\n",
    "A\\\\\n",
    "C\\\\\n",
    "G\\\\\n",
    "T\n",
    "\\end{array}\n",
    "\\overset{T\\quad A\\quad T\\quad A\\quad A\\quad G\\quad C}{\\left[ \\begin{array}{ccccccc}\n",
    "0 & 1 & 0 & 1 & 1 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 0 & 0 & 0 & 1 \\\\\n",
    "0 & 0 & 0 & 0 & 0 & 1 & 0 \\\\\n",
    "1 & 0 & 1 & 0 & 0 & 0 & 0\n",
    "\\end{array}\\right]}\n",
    "$$\n",
    "\n",
    "However, we could equally well represent this sequence using complex numbers. For $j \\geq 1$, let $z_j \\in \\mathbb{C}$ encode our *belief* about the identity of the $j$th base pair in the following way. Enforce $|z_j| \\leq 1$ and identify $z_j = 1$ as full belief that $z_j = \\mathtt{A}$; $z_j = -1$ with $z_j = \\mathtt{T}$; $z_j = i$ with $z_j = \\mathtt{C}$; and $z_j = -i$ with $z_j = \\mathtt{G}$. Then we can represent the same sequence as above in the following way:\n",
    "$$\n",
    "\\vec x := \\overset{T \\quad\\, A \\quad\\, T \\quad\\, A \\quad\\, A \\quad\\, G \\quad\\, C}{\\left[\\begin{array}{ccccccc}\n",
    "-1 & 1 & -1 & 1 & 1 & -i & i\n",
    "\\end{array}\\right]}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that intermediate values (*i.e.,* those that are not equal to $1, -1, i, -1$) can be interpreted still as a *strength of belief* about the identity of that base pair. For example, $(1+i)/\\sqrt{2}$ can be interpreted as an equal belief that the identity of that base pair is either `A` or `C`. One thing we lose is the ability to tell the difference between \"maybe A or T but not C or G\" and \"equal belief for A, C, G, T\". We hope this may not pose a problem, since it is typically very unlikely in real life for A and T to be confused, whereas it is relatively more likely for T and C to be confused or A and G (due to the structure and size of the aromatic ringsÂ that compose them). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reverse Complement\n",
    "\n",
    "The reverse complement of a sequence should be identified by a neural network in the same way as the original strand (due to the way that DNA is built). \n",
    "\n",
    "The reverse complement of `TATAAGC` is `GCTTATA`. This would be encoded by the sequence \n",
    "$$\n",
    "\\vec x_{\\mathrm{RC}} := \\overset{G \\quad\\,\\, C \\quad\\,\\, T \\quad\\,\\, T \\quad\\,\\, A \\quad\\,\\, T \\quad\\,\\, A}{\\left[\\begin{array}{ccccccc}\n",
    "-i & i & -1 & -1 & 1 & -1 & 1\n",
    "%-1 & 1 & -1 & 1 & 1 & -i & i\n",
    "\\end{array}\\right]}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Invariance under convolution\n",
    "\n",
    "We'd like a sequence and its reverse complement to be invariant under convolution so that when we inject a sequence into a neural network, we can expect it to behave the same way as when we inject its reverse complement. \n",
    "\n",
    "First, define the exchange matrix $J_n \\in \\mathbb{R}^{n\\times n}$ by\n",
    "$$\n",
    "(J_n)_{ij} := \\begin{cases}\n",
    "1 & j = n - i + 1\\\\\n",
    "0 & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "so that, for example,\n",
    "$$\n",
    "J_3 := \n",
    "\\left[\\begin{array}{rrr}\n",
    "0 & 0 & 1\\\\\n",
    "0 & 1 & 0\\\\\n",
    "1 & 0 & 0 \n",
    "\\end{array} \\right]\n",
    "$$\n",
    "\n",
    "Next, define $K_n := -J_n$. Note that the sequence $\\vec x$ can be transformed into the sequence $\\vec x_{\\mathrm{RC}}$ by left matrix multiplication with $K_n$:\n",
    "\n",
    "$$\n",
    "\\vec x_{\\mathrm{RC}} = K_n \\vec x\n",
    "$$\n",
    "\n",
    "In particular, if the first layer of a neural network is given by \n",
    "$$\n",
    "h(\\vec x) = \\sigma ( W \\vec x + b ) \n",
    "$$\n",
    "for an activation function $\\sigma$, convolutional matrix $W$ and bias $b$, then we would like to demand that \n",
    "$$\n",
    "\\sigma (W \\vec x + b)  = h(\\vec x) = h(\\vec x_{\\mathrm{RC}}) = \\sigma(W K_n \\vec x + b)\n",
    "$$\n",
    "\n",
    "Writing $W = (w_{i,j})_{i,j}$, this constraint is equivalent to the demand that \n",
    "$$\n",
    "W = W K_n\n",
    "\\quad \\iff \\quad \n",
    "w_{i,j} = -w_{i, n-j+1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps: Viability and interpretability\n",
    "\n",
    "It remains to be determined if this particular architecture is too strict a constraint. Typically, convolutional matrices are in some way structured so that they can carry out the convolution... Would imposing this type of parameter pairing destroy that convolutional structure? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.layers import Conv1D, Dense, Flatten, Input, GlobalMaxPool1D, MaxPool1D, Reshape\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bp_row_dict = {'A': 0, 'T': 3, \n",
    "               'C': 1, 'G': 2}\n",
    "row_bp_dict = {0: 'A', 1: 'C',\n",
    "               2: 'G', 3: 'T'}\n",
    "def _basePairToRow(bp):\n",
    "    return bp_row_dict[bp]\n",
    "def _rowToBasePair(row):\n",
    "    return row_bp_dict[row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rc_dict = {'A': 'T', 'T': 'A',                \n",
    "           'C': 'G', 'G': 'C'}\n",
    "def _reverseComplementOfBasePair(bp):\n",
    "    return rc_dict[bp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "seq -> OH\n",
    "seq -> Complex\n",
    "OH -> Complex\n",
    "OH -> seq\n",
    "\n",
    "\"\"\"\n",
    "def seqToOneHot(seq):\n",
    "    # Returns N-by-4 onehot encoding of sequence\n",
    "    from keras.utils import to_categorical\n",
    "    return to_categorical(list(map(_basePairToRow, seq)), num_classes=4)\n",
    "\n",
    "\n",
    "def seqToComplex(seq):\n",
    "    return oneHotToComplex(seqToOneHot(seq))\n",
    "\n",
    "\n",
    "def idxToComplex(idx):\n",
    "    cplx = np.zeros((len(idx), 2))\n",
    "    cplx[idx < 2, idx[idx < 2]] = 1\n",
    "    cplx[idx>1, idx[idx > 1]-3] = -1\n",
    "    return cplx\n",
    "\n",
    "\n",
    "def oneHotToComplex(oh):\n",
    "    Xr = oh[:, 0] - oh[:, 3] # A - T\n",
    "    Xi = oh[:, 1] - oh[:, 2] # C - G\n",
    "    Xabs = np.sqrt(Xr**2 + Xi**2)\n",
    "    Xr = Xr / Xabs\n",
    "    Xi = Xi / Xabs\n",
    "    return np.column_stack((Xr, Xi))\n",
    "\n",
    "\n",
    "def oneHotToSeq(oh):\n",
    "    rows = np.argmax(oh, axis=-1)\n",
    "    return ''.join(['ACGT'[j] for j in rows])\n",
    "\n",
    "\n",
    "def cplxToOneHot(cplx):\n",
    "    AC = cplx[cplx > 0]\n",
    "    TG = -cplx[cplx < 0]\n",
    "    return np.column_stack((AC, TG))\n",
    "\n",
    "\n",
    "def cplxToSeq(cplx):\n",
    "    oneHotToSeq(cplxToOneHot(cplx))\n",
    "    return\n",
    "\n",
    "\n",
    "def reverseComplementOfComplex(cplx):\n",
    "    return -cplx[::-1, :]\n",
    "\n",
    "\n",
    "def reverseComplementOfSeq(seq):\n",
    "    ''.join(map(_reverseComplementOfBasePair, seq))\n",
    "\n",
    "    \n",
    "def reverseComplementOfOneHot(oh):\n",
    "    return oh[::-1, ::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_samples = 100000\n",
    "sample_length = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rowNumbers = np.random.randint(4, size=n_samples*sample_length).reshape(n_samples, sample_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate([idxToComplex(nums)[np.newaxis, ...] for nums in rowNumbers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random labels\n",
    "y = (np.random.randn(n_samples) > 0).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_seq = Input(shape=(32, 2,), dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Conv1D(16, 8, activation='relu')(input_seq)\n",
    "x = GlobalMaxPool1D()(x)\n",
    "x = Reshape((16,1))(x)\n",
    "x = Conv1D(16, 8, activation='relu', padding='same')(x)\n",
    "x = MaxPool1D()(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "x = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=input_seq, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 32, 2)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 25, 16)            272       \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 16, 1)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 16, 16)            144       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 8, 16)             0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 4,577\n",
      "Trainable params: 4,577\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile('adagrad', 'binary_crossentropy', metrics=['accuracy', 'mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80000 samples, validate on 20000 samples\n",
      "Epoch 1/30\n",
      "5s - loss: 0.6934 - acc: 0.5009 - mean_squared_error: 0.2501 - val_loss: 0.6932 - val_acc: 0.5012 - val_mean_squared_error: 0.2500\n",
      "Epoch 2/30\n",
      "5s - loss: 0.6932 - acc: 0.5018 - mean_squared_error: 0.2500 - val_loss: 0.6932 - val_acc: 0.4958 - val_mean_squared_error: 0.2500\n",
      "Epoch 3/30\n",
      "5s - loss: 0.6931 - acc: 0.5044 - mean_squared_error: 0.2500 - val_loss: 0.6932 - val_acc: 0.4998 - val_mean_squared_error: 0.2501\n",
      "Epoch 4/30\n",
      "5s - loss: 0.6930 - acc: 0.5067 - mean_squared_error: 0.2499 - val_loss: 0.6932 - val_acc: 0.4984 - val_mean_squared_error: 0.2500\n",
      "Epoch 5/30\n",
      "5s - loss: 0.6929 - acc: 0.5094 - mean_squared_error: 0.2499 - val_loss: 0.6934 - val_acc: 0.5017 - val_mean_squared_error: 0.2501\n",
      "Epoch 6/30\n",
      "5s - loss: 0.6929 - acc: 0.5098 - mean_squared_error: 0.2499 - val_loss: 0.6933 - val_acc: 0.4971 - val_mean_squared_error: 0.2501\n",
      "Epoch 7/30\n",
      "5s - loss: 0.6928 - acc: 0.5132 - mean_squared_error: 0.2498 - val_loss: 0.6933 - val_acc: 0.5022 - val_mean_squared_error: 0.2501\n",
      "Epoch 8/30\n",
      "5s - loss: 0.6927 - acc: 0.5121 - mean_squared_error: 0.2498 - val_loss: 0.6934 - val_acc: 0.4988 - val_mean_squared_error: 0.2501\n",
      "Epoch 9/30\n",
      "5s - loss: 0.6926 - acc: 0.5134 - mean_squared_error: 0.2497 - val_loss: 0.6935 - val_acc: 0.4993 - val_mean_squared_error: 0.2502\n",
      "Epoch 10/30\n",
      "5s - loss: 0.6925 - acc: 0.5138 - mean_squared_error: 0.2497 - val_loss: 0.6935 - val_acc: 0.5014 - val_mean_squared_error: 0.2502\n",
      "Epoch 11/30\n",
      "5s - loss: 0.6925 - acc: 0.5162 - mean_squared_error: 0.2497 - val_loss: 0.6935 - val_acc: 0.5000 - val_mean_squared_error: 0.2502\n",
      "Epoch 12/30\n",
      "5s - loss: 0.6924 - acc: 0.5166 - mean_squared_error: 0.2496 - val_loss: 0.6936 - val_acc: 0.5003 - val_mean_squared_error: 0.2502\n",
      "Epoch 13/30\n",
      "5s - loss: 0.6923 - acc: 0.5177 - mean_squared_error: 0.2496 - val_loss: 0.6937 - val_acc: 0.4990 - val_mean_squared_error: 0.2503\n",
      "Epoch 14/30\n",
      "5s - loss: 0.6922 - acc: 0.5172 - mean_squared_error: 0.2495 - val_loss: 0.6937 - val_acc: 0.4984 - val_mean_squared_error: 0.2503\n",
      "Epoch 15/30\n",
      "5s - loss: 0.6922 - acc: 0.5177 - mean_squared_error: 0.2495 - val_loss: 0.6937 - val_acc: 0.4960 - val_mean_squared_error: 0.2503\n",
      "Epoch 16/30\n",
      "5s - loss: 0.6921 - acc: 0.5173 - mean_squared_error: 0.2495 - val_loss: 0.6942 - val_acc: 0.5005 - val_mean_squared_error: 0.2505\n",
      "Epoch 17/30\n",
      "5s - loss: 0.6921 - acc: 0.5192 - mean_squared_error: 0.2495 - val_loss: 0.6939 - val_acc: 0.4964 - val_mean_squared_error: 0.2504\n",
      "Epoch 18/30\n",
      "5s - loss: 0.6920 - acc: 0.5184 - mean_squared_error: 0.2494 - val_loss: 0.6939 - val_acc: 0.4956 - val_mean_squared_error: 0.2504\n",
      "Epoch 19/30\n",
      "5s - loss: 0.6919 - acc: 0.5215 - mean_squared_error: 0.2494 - val_loss: 0.6940 - val_acc: 0.4968 - val_mean_squared_error: 0.2504\n",
      "Epoch 20/30\n",
      "5s - loss: 0.6918 - acc: 0.5210 - mean_squared_error: 0.2493 - val_loss: 0.6939 - val_acc: 0.5023 - val_mean_squared_error: 0.2504\n",
      "Epoch 21/30\n",
      "5s - loss: 0.6919 - acc: 0.5201 - mean_squared_error: 0.2494 - val_loss: 0.6940 - val_acc: 0.4952 - val_mean_squared_error: 0.2504\n",
      "Epoch 22/30\n",
      "5s - loss: 0.6918 - acc: 0.5215 - mean_squared_error: 0.2493 - val_loss: 0.6940 - val_acc: 0.5020 - val_mean_squared_error: 0.2504\n",
      "Epoch 23/30\n",
      "5s - loss: 0.6917 - acc: 0.5208 - mean_squared_error: 0.2493 - val_loss: 0.6940 - val_acc: 0.4992 - val_mean_squared_error: 0.2504\n",
      "Epoch 24/30\n",
      "5s - loss: 0.6917 - acc: 0.5206 - mean_squared_error: 0.2493 - val_loss: 0.6941 - val_acc: 0.4971 - val_mean_squared_error: 0.2505\n",
      "Epoch 25/30\n",
      "5s - loss: 0.6916 - acc: 0.5217 - mean_squared_error: 0.2493 - val_loss: 0.6943 - val_acc: 0.4962 - val_mean_squared_error: 0.2506\n",
      "Epoch 26/30\n",
      "5s - loss: 0.6916 - acc: 0.5212 - mean_squared_error: 0.2492 - val_loss: 0.6943 - val_acc: 0.4965 - val_mean_squared_error: 0.2505\n",
      "Epoch 27/30\n",
      "5s - loss: 0.6915 - acc: 0.5227 - mean_squared_error: 0.2492 - val_loss: 0.6945 - val_acc: 0.4963 - val_mean_squared_error: 0.2507\n",
      "Epoch 28/30\n",
      "5s - loss: 0.6915 - acc: 0.5236 - mean_squared_error: 0.2492 - val_loss: 0.6943 - val_acc: 0.4966 - val_mean_squared_error: 0.2506\n",
      "Epoch 29/30\n",
      "5s - loss: 0.6914 - acc: 0.5226 - mean_squared_error: 0.2491 - val_loss: 0.6944 - val_acc: 0.4998 - val_mean_squared_error: 0.2506\n",
      "Epoch 30/30\n",
      "6s - loss: 0.6914 - acc: 0.5232 - mean_squared_error: 0.2491 - val_loss: 0.6944 - val_acc: 0.4985 - val_mean_squared_error: 0.2506\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11be69ef0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X, y=y, epochs=30, validation_split=.2, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze weights and responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stackFilters(w):\n",
    "    return np.column_stack(w.transpose((2,0,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1305894a8>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQQAAAOfCAYAAAAuNr2jAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJFtZB968j7MAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x130397048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(stackFilters(W[0]).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rc = np.concatenate([reverseComplementOfComplex(x)[np.newaxis, ...] for x in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_rc_proba = model.predict(X_rc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_rc_pred = (y_rc_proba > 0).astype(int) - (y_rc_proba < 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49980999999999998"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y, y_rc_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now to make the parameter tying happen..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal: write a keras constraint function that takes care of the weight tying within the same layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fancier possibilities\n",
    "\n",
    "In looking for how to handle complex variables in keras, I came across [this paper](https://arxiv.org/pdf/1612.04642.pdf) that defines Harmonic Networks. Associated code is [available here](https://github.com/deworrall92/harmonicConvolutions). It appears at a cursory glance as though such networks could be useful for invariance to reverse complement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "83px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
